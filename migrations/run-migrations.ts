import { Pool } from 'pg';
import knex from 'knex';
import knexConfig from './knexfile';

const pool = new Pool({
  connectionString: process.env.DATABASE_URL || `postgresql://postgres:${process.env.POSTGRES_PASSWORD || 'postgres_dev'}@localhost:5432/postgres`,
});

async function waitForDatabase(maxRetries = 60, delay = 2000) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      await pool.query('SELECT 1');
      console.log('âœ… Database is ready');
      return;
    } catch (error: unknown) {
      const msg = error instanceof Error ? error.message : String(error);
      console.log(`â³ Waiting for database... (${i + 1}/${maxRetries}) ${msg}`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  throw new Error('Database is not available after maximum retries');
}

async function runMigrations() {
  const env = process.env.NODE_ENV || 'development';
  const db = knex(knexConfig[env]);
  
  try {
    console.log('ðŸ”„ Running database migrations...');
    console.log(`ðŸ“ Migrations directory: ${knexConfig[env].migrations?.directory}`);
    
    // Wait for database to be ready
    await waitForDatabase();
    
    // Get list of migration files - migrate.list() returns [completed, pending]
    const [completed, pending] = await db.migrate.list();
    
    // Extract migration names from objects
    const executed = completed.map((m: any) => m.name || (typeof m === 'string' ? m : null)).filter(Boolean);
    const pendingNames = pending.map((m: any) => m.name || (typeof m === 'string' ? m : null)).filter(Boolean);
    
    console.log(`\nðŸ“‹ Migration status:`);
    console.log(`   - Executed: ${executed.length}`);
    console.log(`   - Pending: ${pendingNames.length}`);
    
    if (executed.length > 0) {
      console.log(`\nâœ… Executed migrations:`);
      executed.forEach((name: string) => {
        console.log(`   - ${name}`);
      });
    }
    
    if (pendingNames.length > 0) {
      console.log(`\nâ³ Pending migrations:`);
      pendingNames.forEach((name: string) => {
        console.log(`   - ${name}`);
      });
    }
    
    // Run migrations
    const [batchNo, migrations] = await db.migrate.latest();
    
    if (migrations.length === 0) {
      console.log('\nâ„¹ï¸  No new migrations to run');
    } else {
      console.log(`\nâœ… Applied ${migrations.length} migration(s) in batch ${batchNo}:`);
      migrations.forEach((migration: string) => {
        console.log(`   - ${migration}`);
      });
    }
    
    console.log('\nâœ… Migrations completed successfully');

    // Ð”ÐµÐ¼Ð¾-Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð·Ð´Ð°ÑŽÑ‚ÑÑ ÑÐ¸Ð´Ð°Ð¼Ð¸ (001_initial_data, 002_demo_access), Ð½Ðµ Ð¼Ð¸Ð³Ñ€Ð°Ñ†Ð¸ÑÐ¼Ð¸.
    // Ð¡Ð¸Ð´Ñ‹ Ð¸Ð´ÐµÐ¼Ð¿Ð¾Ñ‚ÐµÐ½Ñ‚Ð½Ñ‹: 001 â€” merge; 002 â€” ÑÐ¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð´ÐµÐ¼Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ demo-workspace ÐµÑ‰Ñ‘ Ð½ÐµÑ‚.
    console.log('\nðŸŒ± Running database seeds (001, 002 demo + chats, 003 extra demo deals)...');
    try {
      await db.seed.run();
      console.log('âœ… Seeds completed successfully');
    } catch (error: any) {
      console.error('âš ï¸  Error running seeds:', error.message || error);
      // Don't fail the whole process if seeds fail
    }
  } catch (error: any) {
    console.error('âŒ Error running migrations:', error.message || error);
    if (error.stack) {
      console.error('Stack:', error.stack);
    }
    throw error;
  } finally {
    await db.destroy();
    await pool.end();
  }
}

runMigrations().catch((error) => {
  console.error('Fatal error:', error);
  process.exit(1);
});
