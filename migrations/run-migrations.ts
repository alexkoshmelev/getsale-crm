import { Pool } from 'pg';
import knex from 'knex';
import knexConfig from './knexfile';

const pool = new Pool({
  connectionString: process.env.DATABASE_URL || `postgresql://postgres:${process.env.POSTGRES_PASSWORD || 'postgres_dev'}@localhost:5432/postgres`,
});

async function waitForDatabase(maxRetries = 60, delay = 2000) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      await pool.query('SELECT 1');
      console.log('âœ… Database is ready');
      return;
    } catch (error: unknown) {
      const msg = error instanceof Error ? error.message : String(error);
      console.log(`â³ Waiting for database... (${i + 1}/${maxRetries}) ${msg}`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  throw new Error('Database is not available after maximum retries');
}

async function runMigrations() {
  const env = process.env.NODE_ENV || 'development';
  const db = knex(knexConfig[env]);
  
  try {
    console.log('ðŸ”„ Running database migrations...');
    console.log(`ðŸ“ Migrations directory: ${knexConfig[env].migrations?.directory}`);
    
    // Wait for database to be ready
    await waitForDatabase();
    
    // Get list of migration files - migrate.list() returns [completed, pending]
    const [completed, pending] = await db.migrate.list();
    
    // Extract migration names from objects
    const executed = completed.map((m: any) => m.name || (typeof m === 'string' ? m : null)).filter(Boolean);
    const pendingNames = pending.map((m: any) => m.name || (typeof m === 'string' ? m : null)).filter(Boolean);
    
    console.log(`\nðŸ“‹ Migration status:`);
    console.log(`   - Executed: ${executed.length}`);
    console.log(`   - Pending: ${pendingNames.length}`);
    
    if (executed.length > 0) {
      console.log(`\nâœ… Executed migrations:`);
      executed.forEach((name: string) => {
        console.log(`   - ${name}`);
      });
    }
    
    if (pendingNames.length > 0) {
      console.log(`\nâ³ Pending migrations:`);
      pendingNames.forEach((name: string) => {
        console.log(`   - ${name}`);
      });
    }
    
    // Run migrations
    const [batchNo, migrations] = await db.migrate.latest();
    
    if (migrations.length === 0) {
      console.log('\nâ„¹ï¸  No new migrations to run');
    } else {
      console.log(`\nâœ… Applied ${migrations.length} migration(s) in batch ${batchNo}:`);
      migrations.forEach((migration: string) => {
        console.log(`   - ${migration}`);
      });
    }
    
    console.log('\nâœ… Migrations completed successfully');
    
    // Run seeds after migrations (only if no seeds have been run yet, or if explicitly requested)
    // Check if seeds have been run by checking if default organization exists
    const orgExists = await db('organizations')
      .where({ slug: 'default-org' })
      .first();
    
    const shouldRunSeeds = !orgExists || process.env.FORCE_SEED === 'true';
    
    if (shouldRunSeeds) {
      console.log('\nðŸŒ± Running database seeds...');
      try {
        await db.seed.run();
        console.log('âœ… Seeds completed successfully');
      } catch (error: any) {
        console.error('âš ï¸  Error running seeds:', error.message || error);
        // Don't fail the whole process if seeds fail
      }
    } else {
      console.log('\nâ„¹ï¸  Seeds already exist, skipping seed run. Set FORCE_SEED=true to force seeding.');
    }
  } catch (error: any) {
    console.error('âŒ Error running migrations:', error.message || error);
    if (error.stack) {
      console.error('Stack:', error.stack);
    }
    throw error;
  } finally {
    await db.destroy();
    await pool.end();
  }
}

runMigrations().catch((error) => {
  console.error('Fatal error:', error);
  process.exit(1);
});
